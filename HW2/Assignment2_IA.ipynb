{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the convolution function from Assignment 1\n",
    "def convolution_image(input_image, conv_kernel):  \n",
    "    # Kernel dimension\n",
    "    x_kern = conv_kernel.shape[0]\n",
    "    y_kern = conv_kernel.shape[1]\n",
    "    \n",
    "    # Kernel is flipped both horizontally and vertically\n",
    "    kernel_lr = np.fliplr(conv_kernel)\n",
    "    conv_kernel = np.flipud(kernel_lr)\n",
    "    \n",
    "    # Add zero padding to the input image\n",
    "    input_image_pad = np.zeros((input_image.shape[0] + 2, input_image.shape[1] + 2))\n",
    "    input_image_pad[1:-1, 1:-1] = input_image\n",
    "    \n",
    "    # Initialize the output image of convolution\n",
    "    conv_output = np.zeros_like(input_image)\n",
    "\n",
    "    # For every pixel of the image, do multiplication with the kernel\n",
    "    for m in range(input_image.shape[1]):\n",
    "        for n in range(input_image.shape[0]):\n",
    "            conv_output[n, m]=(conv_kernel * input_image_pad[n: n + y_kern, m: m + x_kern]).sum()\n",
    "\n",
    "    return conv_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q1: Filter \n",
    "kernel_posneg = np.array([[0,-1/4,0], [-1/4,0,-1/4], [0,-1/4,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2: Filter \n",
    "kernel_xgrad = np.array([[0,-1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Q3: Transformations in Frequency Domain\n",
    "## Read the image\n",
    "img = cv2.imread(\"sample1.jpg\",0)\n",
    "cv2.imwrite('sample1_gray.jpg',img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3.1 and Q3.2 Defining horizontal and vertical edge detection filter\n",
    "horizontal_edge_fl = np.array([[+1,+2,+1], [0,0,0], [-1,-2,-1]])\n",
    "vertical_edge_fl = np.array([[-1,0,+1], [-2,0,+2], [-1,0,+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### How horizontal and vertical edge filters work on the image (Convolving them with the image in spatial domain)\n",
    "img_hor_edge = convolution_image(img,horizontal_edge_fl)\n",
    "cv2.imwrite('sample1_conv_hor_edge.jpg',img_hor_edge) \n",
    "\n",
    "img_ver_edge = convolution_image(img,vertical_edge_fl)\n",
    "cv2.imwrite('sample1_conv_ver_edge.jpg',img_ver_edge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-6f4a14d35207>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  f_horizontal_fdomain = 20 * np.log(np.abs(f_horizontal_shift))\n",
      "<ipython-input-64-6f4a14d35207>:8: RuntimeWarning: divide by zero encountered in log\n",
      "  f_vertical_fdomain = 20 * np.log(np.abs(f_vertical_shift))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q3.3 Frequency domain transformation of vertical and horizontal filters\n",
    "f_horizontal = fftpack.fft2(horizontal_edge_fl)\n",
    "f_horizontal_shift = fftpack.fftshift(f_horizontal)\n",
    "f_horizontal_fdomain = 20 * np.log(np.abs(f_horizontal_shift))\n",
    "\n",
    "f_vertical = fftpack.fft2(vertical_edge_fl)\n",
    "f_vertical_shift = fftpack.fftshift(f_vertical)\n",
    "f_vertical_fdomain = 20 * np.log(np.abs(f_vertical_shift))\n",
    "\n",
    "cv2.imwrite('hor_edge_filter_fft.jpg',f_horizontal_fdomain) \n",
    "cv2.imwrite('ver_edge_filter_fft.jpg',f_vertical_fdomain) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q3.4 Frequency domain transformation of the image\n",
    "f_img = fftpack.fft2(img)\n",
    "f_img_shift = fftpack.fftshift(f_img)\n",
    "f_img_fdomain = 20 * np.log(np.abs(f_img_shift))\n",
    "\n",
    "cv2.imwrite('sample1_fft.jpg',f_img_fdomain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 321)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Q3.5 and Q3.6 Transformation into frequency domain and then conversion into spatial domain\n",
    "### This is for the horizontal edge filter\n",
    "kernel_hor_edge = np.array([[+1,+2,+1], [0,0,0], [-1,-2,-1]]) ## Same as horizontal_edge_fl\n",
    "\n",
    "sz = (img.shape[0] - kernel_hor_edge.shape[0], img.shape[1] - kernel_hor_edge.shape[1])  ## total amount of padding for the filter\n",
    "kernel_hor_edge = np.pad(kernel_hor_edge, (((sz[0]+1)//2, sz[0]//2), ((sz[1]+1)//2, sz[1]//2)), 'constant') ## Add the padding to the filter\n",
    "print(kernel_hor_edge.shape)\n",
    "\n",
    "kernel_hor_edge = fftpack.ifftshift(kernel_hor_edge)\n",
    "inv_fdomain_hor = np.real(fftpack.ifft2(f_img * fftpack.fft2(kernel_hor_edge)))+ np.imag(fftpack.ifft2(f_img * fftpack.fft2(kernel_hor_edge)))\n",
    "\n",
    "cv2.imwrite('sample1_hor_fft.jpg',inv_fdomain_hor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 321)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Q3.5 and Q3.6 Transformation into frequency domain and then conversion into spatial domain\n",
    "### This is for the vertical edge filter\n",
    "kernel_ver_edge = np.array([[-1,0,+1], [-2,0,+2], [-1,0,+1]]) ## Same as vertical_edge_fl\n",
    "\n",
    "sz = (img.shape[0] - kernel_ver_edge.shape[0], img.shape[1] - kernel_ver_edge.shape[1])  ## total amount of padding for the filter\n",
    "kernel_ver_edge = np.pad(kernel_ver_edge, (((sz[0]+1)//2, sz[0]//2), ((sz[1]+1)//2, sz[1]//2)), 'constant') ## Add the padding to the filter\n",
    "print(kernel_ver_edge.shape)\n",
    "\n",
    "kernel_ver_edge = fftpack.ifftshift(kernel_ver_edge)\n",
    "inv_domain_ver = np.real(fftpack.ifft2(f_img * fftpack.fft2(kernel_ver_edge)))+ np.imag(fftpack.ifft2(f_img * fftpack.fft2(kernel_ver_edge)))\n",
    "\n",
    "cv2.imwrite('sample1_ver_fft.jpg',inv_domain_ver) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_addn = np.sqrt(np.square(inv_domain_ver) + np.square(inv_fdomain_hor))\n",
    "spatial_addn *= 255.0 / spatial_addn.max()\n",
    "cv2.imwrite('sample1_final.jpg',spatial_addn) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
